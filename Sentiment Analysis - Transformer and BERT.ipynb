{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aab9a569",
      "metadata": {
        "id": "aab9a569"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b8190b19",
      "metadata": {
        "id": "b8190b19"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
        "                                  untar=True, cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DvQNvnr02MC",
        "outputId": "23ee6b1e-2b94-4b83-88e5-2e0877131e31"
      },
      "id": "5DvQNvnr02MC",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README', 'test', 'imdb.vocab', 'train', 'imdbEr.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA4T9l6R02OX",
        "outputId": "8ba1c215-42c9-4ed5-e0c2-2ab73a015991"
      },
      "id": "BA4T9l6R02OX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unsup',\n",
              " 'labeledBow.feat',\n",
              " 'urls_pos.txt',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'urls_unsup.txt',\n",
              " 'urls_neg.txt',\n",
              " 'unsupBow.feat']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "metadata": {
        "id": "Pjth0RHA02S4"
      },
      "id": "Pjth0RHA02S4",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fafaf36e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fafaf36e",
        "outputId": "33a51810-e86b-4b1a-ff5a-f56a6cfb9a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1024\n",
        "seed = 12345\n",
        "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "                            'aclImdb/train', batch_size=batch_size, \n",
        "                            validation_split=0.2,\n",
        "                            subset='training', seed=seed)\n",
        "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "                            'aclImdb/train', batch_size=batch_size, \n",
        "                            validation_split=0.2,\n",
        "                            subset='validation', seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fed87acf",
      "metadata": {
        "id": "fed87acf"
      },
      "outputs": [],
      "source": [
        "vocab_size   = 20000\n",
        "sequence_len = 200\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
        "    )\n",
        "\n",
        "vectorization = tf.keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_len,\n",
        ")\n",
        "\n",
        "vectorization.adapt(train_ds.map(lambda text, label: text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eaa2d5a2",
      "metadata": {
        "id": "eaa2d5a2"
      },
      "outputs": [],
      "source": [
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorization(text), label\n",
        "\n",
        "train_ds = train_ds.map(vectorize_text)\n",
        "val_ds = val_ds.map(vectorize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2486508b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2486508b",
        "outputId": "4e90366f-73e7-4af2-c9e9-356d7f04da57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[ 2340  4688   447     1     2     1  7756  4688   674     1     2     1\n",
            "   167     1     5  5953     3  2730  2050  3250    14 16623    14  7824\n",
            " 17408   510  2886     5 16708     1   967 15850 10635    31     2  1413\n",
            "     5    29     1 15602  2177   293    33 12974  3768     5   656    35\n",
            "     2  1947  3275  1753  1719     6   938    11  7175   111   619     6\n",
            "    65 14406     2  3958  9106     5     2 10635    24  1264   203  1305\n",
            "     8  4970  7573  3367     2   676     5   253   230     6  7948   154\n",
            " 17408   379  1440   350     5  1041 16824     3  5459  1619   450     2\n",
            "   278  2482    16  4863  3678   982  2289     3  6520  9790   742  3863\n",
            "   881   300     6     2  7856 15594     5   619   846     3 11474   230\n",
            "  5838     5     1 18551   450     2  1988  9394     2  1674     5     2\n",
            "   223     6    29    85  5080 15602 17921    30     1    20    23   904\n",
            "    35     2   295  9632     5  3604  9614  3795     8  1831  2411     6\n",
            "   467     1  1152    16    65 18858     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds:\n",
        "    print(label_batch[0].numpy())\n",
        "    print(text_batch.numpy()[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2a8a2783",
      "metadata": {
        "id": "2a8a2783"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5484718e",
      "metadata": {
        "id": "5484718e"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cffe32c7",
      "metadata": {
        "id": "cffe32c7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1a727afd",
      "metadata": {
        "id": "1a727afd"
      },
      "outputs": [],
      "source": [
        "# Two seperate embedding layers, one for tokens, one for token index (positions)\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "68667876",
      "metadata": {
        "id": "68667876"
      },
      "outputs": [],
      "source": [
        "embed_dim = 128  # Embedding size for each token\n",
        "num_heads = 6    # Number of attention heads\n",
        "ff_dim = 128     # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "embedding_layer = TokenAndPositionEmbedding(sequence_len, vocab_size, embed_dim)\n",
        "transformer_block1 = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "transformer_block2 = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "\n",
        "inputs = layers.Input(shape=(sequence_len,))\n",
        "x = embedding_layer(inputs)\n",
        "x = transformer_block1(x)\n",
        "x = transformer_block2(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0cd01ada",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cd01ada",
        "outputId": "592258aa-372a-4983-d143-e920b4a68041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 37s 1s/step - loss: 0.7419 - accuracy: 0.5076 - val_loss: 0.6925 - val_accuracy: 0.5598\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 22s 1s/step - loss: 0.6889 - accuracy: 0.5350 - val_loss: 0.6729 - val_accuracy: 0.6032\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 23s 1s/step - loss: 0.5380 - accuracy: 0.7174 - val_loss: 0.3687 - val_accuracy: 0.8434\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 23s 1s/step - loss: 0.2654 - accuracy: 0.9004 - val_loss: 0.3152 - val_accuracy: 0.8792\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 24s 1s/step - loss: 0.1833 - accuracy: 0.9305 - val_loss: 0.3436 - val_accuracy: 0.8714\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.1501 - accuracy: 0.9452 - val_loss: 0.3670 - val_accuracy: 0.8628\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 26s 1s/step - loss: 0.0757 - accuracy: 0.9755 - val_loss: 0.6679 - val_accuracy: 0.8382\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.0909 - accuracy: 0.9656 - val_loss: 0.5463 - val_accuracy: 0.8496\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.1317 - accuracy: 0.9478 - val_loss: 0.5552 - val_accuracy: 0.8012\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.0579 - accuracy: 0.9801 - val_loss: 0.7022 - val_accuracy: 0.8604\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.6980 - val_accuracy: 0.8404\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 27s 1s/step - loss: 0.0331 - accuracy: 0.9883 - val_loss: 0.7369 - val_accuracy: 0.8434\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.6952 - val_accuracy: 0.8480\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 26s 1s/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.7735 - val_accuracy: 0.8532\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.8557 - val_accuracy: 0.8544\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.9023 - val_accuracy: 0.8524\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.9118 - val_accuracy: 0.8524\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.9429 - val_accuracy: 0.8524\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 26s 1s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.9557 - val_accuracy: 0.8518\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.9684 - val_accuracy: 0.8518\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(train_ds, batch_size=32, epochs=20, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-trained BERT"
      ],
      "metadata": {
        "id": "c4tprRtTSJwJ"
      },
      "id": "c4tprRtTSJwJ"
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
        "                                  untar=True, cache_dir='.',\n",
        "                                  cache_subdir='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOe91Bp4WGrv",
        "outputId": "103c52de-5f5f-4caa-c3ec-a2c46beea5b4"
      },
      "id": "VOe91Bp4WGrv",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "os.listdir(dataset_dir)\n",
        "\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)\n",
        "\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "metadata": {
        "id": "v0rq8C2cWG-H"
      },
      "id": "v0rq8C2cWG-H",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "seed = 12345\n",
        "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "                            'aclImdb/train', batch_size=batch_size, \n",
        "                            validation_split=0.2,\n",
        "                            subset='training', seed=seed)\n",
        "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "                            'aclImdb/train', batch_size=batch_size, \n",
        "                            validation_split=0.2,\n",
        "                            subset='validation', seed=seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPgT-s7nWHAw",
        "outputId": "3388d099-6b95-462d-8838-abd9df2ee3e4"
      },
      "id": "CPgT-s7nWHAw",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_ds:\n",
        "    print(label_batch[0].numpy())\n",
        "    print(text_batch[0].numpy().decode())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVAtaQ8MWHCt",
        "outputId": "0bcf68f7-b3d6-4d8b-bb09-0fe0c3223a90"
      },
      "id": "pVAtaQ8MWHCt",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "When we talk Hollywood Hotel we could be talking about one of three things, the actual hotel, the radio program, and this film which was partially inspired by the first two. Dick Powell was the host of the Hollywood Hotel program on CBS radio network in which Louella Parsons dished out the weekly scoop on the stars.<br /><br />Powell and Parsons debuted the Hollywood Hotel program in 1934 so by 1937 it had its fair share of the radio audience. Powell hosted, sang, and kibitzed with Louella and her movie star guests. With the power she had with her column, she was able to get the various stars to go on and plug their latest films for nothing.<br /><br />Then the American Federation of Radio Artists stepped in and demanded she pay wages accordingly and they won the case. That ended the Hollywood Hotel program in 1938. Of course both Powell and Louella went on to other radio venues. The whole story is covered in the Tony Thomas book, The Films Of Dick Powell.<br /><br />But before the plug was pulled this film came out from Powell's home studio of Warner Brothers inspired by the radio program. Powell plays a singer/saxophonist with the Benny Goodman band who gets signed to a Hollywood contract. But when he gets out to Hollywood he gets himself tangled up with an egotistical film star Lola Lane, her lookalike double real life sister Rosemary Lane, and a ham actor in Alan Mowbray.<br /><br />When Mowbray is called upon to sing in a Civil War epic he's making with Lola Lane, it's Powell's voice they use. Then Mowbray develops a Lina Lamont problem when he's asked to go on the Hollywood Hotel radio program, broadcast from the Hollywood Hotel. That's got the studio in a tizzy. Let's say the problem isn't solved the way it is Singing In The Rain, but Powell's manager Ted Healy proves to be resourceful.<br /><br />Richard Whiting and Johnny Mercer provide a really nice score for the film. The big hit song comes right at the beginning as the Benny Goodman band with scat singing Johnnie Davis sing Hollywood's anthem, Hooray for Hollywood. My favorite however is Powell and Rosemary Lane singing, I'm Like A Fish Out Of Water. Just listening to Johnny Mercer's lyrics about Ginger Rogers running the Brooklyn Dodgers or Sally Rand without her fan, it's a compendium of American popular culture in the Thirties.<br /><br />Busby Berkeley does the choreography here and while the film doesn't have the soaring imaginary stuff that his earlier work with Warner Brothers has, the numbers are well staged. Berkeley's big moment is in a drive-in eatery where Powell and Healy have been forced to take jobs. The number starts with Benny Goodman broadcasting from the Hollywood Hotel doing Let That Be A Lesson To You and then at the drive-in Powell, Lane and the entire place start joining in song to the exasperation of owner Edgar Kennedy. And you know what you can expect from Edgar Kennedy exasperation.<br /><br />Benny Goodman gets to show why he was named the King Of Swing when the band with drummer Gene Krupa and xylophonist Lionel Hampton as part of his ensemble. That together with Frances Langford singing as well. And possibly the last surviving cast member of the group was a fellow who had a small bit as a radio announcer. He died in 2004, but not before he became the 40th President of the United States. Ronald Reagan always credited Dick Powell and Pat O'Brien as being the two guys on Warner Brothers who were the most helpful to an eager young player looking to make his mark.<br /><br />Hollywood Hotel is one delightful and entertaining motion picture, dated, but charmingly so.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q080a7inSL1t",
        "outputId": "159d59e6-5326-4f4f-9429-b6c4dd728fd1"
      },
      "id": "q080a7inSL1t",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "\n",
        "def convert_text_to_feature(review, tokenizer, max_length):  \n",
        "    return tokenizer.encode_plus(review,\n",
        "                                add_special_tokens=True,\n",
        "                                max_length = max_length,\n",
        "                                padding='max_length',\n",
        "                                truncation=True,\n",
        "                                return_attention_mask=True)\n",
        "\n",
        "def map_feature_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
        "    return {\"input_ids\": input_ids,\n",
        "            \"token_type_ids\": token_type_ids,\n",
        "            \"attention_mask\": attention_masks,}, label\n",
        "\n",
        "def encode_text(ds, tokenizer, max_length):\n",
        "    input_ids_list = []\n",
        "    token_type_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    label_list = []\n",
        "        \n",
        "    for review, label in ds:\n",
        "        bert_input = convert_text_to_feature(review[0].numpy().decode(), tokenizer, max_length)\n",
        "    \n",
        "        input_ids_list.append(bert_input['input_ids'])\n",
        "        token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "        attention_mask_list.append(bert_input['attention_mask'])\n",
        "        label_list.append([label[0].numpy()])\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices(\n",
        "                (input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_feature_to_dict)"
      ],
      "metadata": {
        "id": "OJVG_gXzSNMI"
      },
      "id": "OJVG_gXzSNMI",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512\n",
        "learning_rate = 2e-5\n",
        "epochs = 5\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ],
      "metadata": {
        "id": "VSpZDnhPSPw_"
      },
      "id": "VSpZDnhPSPw_",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode_plus(text_batch[0].numpy().decode(),\n",
        "                      add_special_tokens = True,\n",
        "                      max_length = max_length,\n",
        "                      padding='max_length',\n",
        "                      truncation=True,\n",
        "                      return_attention_mask = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXwDVeoMSTBv",
        "outputId": "61f5633d-6a6d-4eef-91a5-30651e033fe2"
      },
      "id": "tXwDVeoMSTBv",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2043, 2057, 2831, 5365, 3309, 2057, 2071, 2022, 3331, 2055, 2028, 1997, 2093, 2477, 1010, 1996, 5025, 3309, 1010, 1996, 2557, 2565, 1010, 1998, 2023, 2143, 2029, 2001, 6822, 4427, 2011, 1996, 2034, 2048, 1012, 5980, 8997, 2001, 1996, 3677, 1997, 1996, 5365, 3309, 2565, 2006, 6568, 2557, 2897, 1999, 2029, 10223, 8411, 13505, 9841, 2098, 2041, 1996, 4882, 23348, 2006, 1996, 3340, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 8997, 1998, 13505, 6006, 1996, 5365, 3309, 2565, 1999, 4579, 2061, 2011, 4347, 2009, 2018, 2049, 4189, 3745, 1997, 1996, 2557, 4378, 1012, 8997, 4354, 1010, 6369, 1010, 1998, 11382, 16313, 5422, 2007, 10223, 8411, 1998, 2014, 3185, 2732, 6368, 1012, 2007, 1996, 2373, 2016, 2018, 2007, 2014, 5930, 1010, 2016, 2001, 2583, 2000, 2131, 1996, 2536, 3340, 2000, 2175, 2006, 1998, 13354, 2037, 6745, 3152, 2005, 2498, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2059, 1996, 2137, 4657, 1997, 2557, 3324, 3706, 1999, 1998, 6303, 2016, 3477, 12678, 11914, 1998, 2027, 2180, 1996, 2553, 1012, 2008, 3092, 1996, 5365, 3309, 2565, 1999, 4260, 1012, 1997, 2607, 2119, 8997, 1998, 10223, 8411, 2253, 2006, 2000, 2060, 2557, 9356, 1012, 1996, 2878, 2466, 2003, 3139, 1999, 1996, 4116, 2726, 2338, 1010, 1996, 3152, 1997, 5980, 8997, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2021, 2077, 1996, 13354, 2001, 2766, 2023, 2143, 2234, 2041, 2013, 8997, 1005, 1055, 2188, 2996, 1997, 6654, 3428, 4427, 2011, 1996, 2557, 2565, 1012, 8997, 3248, 1037, 3220, 1013, 19977, 2007, 1996, 11945, 14514, 2316, 2040, 4152, 2772, 2000, 1037, 5365, 3206, 1012, 2021, 2043, 2002, 4152, 2041, 2000, 5365, 2002, 4152, 2370, 14170, 2039, 2007, 2019, 13059, 16774, 7476, 2143, 2732, 15137, 4644, 1010, 2014, 2298, 11475, 3489, 3313, 2613, 2166, 2905, 18040, 4644, 1010, 1998, 1037, 10654, 3364, 1999, 5070, 9587, 2860, 10024, 2100, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2043, 9587, 2860, 10024, 2100, 2003, 2170, 2588, 2000, 6170, 1999, 1037, 2942, 2162, 8680, 2002, 1005, 1055, 2437, 2007, 15137, 4644, 1010, 2009, 1005, 1055, 8997, 1005, 1055, 2376, 2027, 2224, 1012, 2059, 9587, 2860, 10024, 2100, 11791, 1037, 27022, 16983, 12162, 3291, 2043, 2002, 1005, 1055, 2356, 2000, 2175, 2006, 1996, 5365, 3309, 2557, 2565, 1010, 3743, 2013, 1996, 5365, 3309, 1012, 2008, 1005, 1055, 2288, 1996, 2996, 1999, 1037, 14841, 28753, 1012, 2292, 1005, 1055, 2360, 1996, 3291, 3475, 1005, 1056, 13332, 1996, 2126, 2009, 2003, 4823, 1999, 1996, 4542, 1010, 2021, 8997, 1005, 1055, 3208, 6945, 25706, 16481, 2000, 2022, 7692, 3993, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2957, 1059, 27798, 3070, 1998, 5206, 13081, 3073, 1037, 2428, 3835, 3556, 2005, 1996, 2143, 1012, 1996, 2502, 2718, 2299, 3310, 2157, 2012, 1996, 2927, 2004, 1996, 11945, 14514, 2316, 2007, 8040, 4017, 4823, 27716, 4482, 6170, 5365, 1005, 1055, 11971, 1010, 7570, 6525, 2100, 2005, 5365, 1012, 2026, 5440, 2174, 2003, 8997, 1998, 18040, 4644, 4823, 1010, 1045, 1005, 1049, 2066, 1037, 3869, 2041, 1997, 2300, 1012, 2074, 5962, 2000, 5206, 13081, 1005, 1055, 4581, 2055, 14580, 7369, 2770, 1996, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_ds = encode_text(train_ds, tokenizer, max_length).shuffle(32).batch(batch_size)\n",
        "val_ds = encode_text(val_ds, tokenizer, max_length).batch(batch_size)"
      ],
      "metadata": {
        "id": "b4OO0gnwSUoK"
      },
      "id": "b4OO0gnwSUoK",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "a32089aa192c43e798ec656f86e16f3d",
            "adc4236e46c441b48e7fd86d2a8bc19b",
            "de20a9d6944540549a5ce5afe2d1745d",
            "f391a5a1a79a478a95df56dd9e2cc35e",
            "59825bac174e41c19cff080e76c084cd",
            "74a419fa23d0410eab42cdd2e7f6c6df",
            "198d7c7c59804e12bfd1d5a07a65093b",
            "c1aded53fb8d4da99702a596aa0ace18",
            "97f061e6e6f845958207f9488f902b99",
            "174c0cd51c37474bb926a7025a69b77f",
            "dfe9039641a1470ba20e623bbc5a30ff"
          ]
        },
        "id": "mV32VY_gSW01",
        "outputId": "4fae2604-32cf-441a-dc1d-a57001709d52"
      },
      "id": "mV32VY_gSW01",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/536M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a32089aa192c43e798ec656f86e16f3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  109482240 \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  1538      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08), \n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n",
        ")\n",
        "\n",
        "history = model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S21GHjzOSYS2",
        "outputId": "7442f57d-54e4-4cb6-e9d1-795dde5a7663"
      },
      "id": "S21GHjzOSYS2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2500/2500 [==============================] - 2596s 1s/step - loss: 0.1206 - accuracy: 0.9580 - val_loss: 0.2119 - val_accuracy: 0.9268\n",
            "Epoch 2/5\n",
            "2500/2500 [==============================] - 2603s 1s/step - loss: 0.0597 - accuracy: 0.9818 - val_loss: 0.2514 - val_accuracy: 0.9264\n",
            "Epoch 3/5\n",
            "2500/2500 [==============================] - 2608s 1s/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 0.2690 - val_accuracy: 0.9290\n",
            "Epoch 4/5\n",
            "2500/2500 [==============================] - 2547s 1s/step - loss: 0.0326 - accuracy: 0.9888 - val_loss: 0.3019 - val_accuracy: 0.9286\n",
            "Epoch 5/5\n",
            " 850/2500 [=========>....................] - ETA: 25:45 - loss: 0.0274 - accuracy: 0.9897"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a32089aa192c43e798ec656f86e16f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adc4236e46c441b48e7fd86d2a8bc19b",
              "IPY_MODEL_de20a9d6944540549a5ce5afe2d1745d",
              "IPY_MODEL_f391a5a1a79a478a95df56dd9e2cc35e"
            ],
            "layout": "IPY_MODEL_59825bac174e41c19cff080e76c084cd"
          }
        },
        "adc4236e46c441b48e7fd86d2a8bc19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a419fa23d0410eab42cdd2e7f6c6df",
            "placeholder": "​",
            "style": "IPY_MODEL_198d7c7c59804e12bfd1d5a07a65093b",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "de20a9d6944540549a5ce5afe2d1745d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1aded53fb8d4da99702a596aa0ace18",
            "max": 536063208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97f061e6e6f845958207f9488f902b99",
            "value": 536063208
          }
        },
        "f391a5a1a79a478a95df56dd9e2cc35e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_174c0cd51c37474bb926a7025a69b77f",
            "placeholder": "​",
            "style": "IPY_MODEL_dfe9039641a1470ba20e623bbc5a30ff",
            "value": " 536M/536M [00:06&lt;00:00, 80.9MB/s]"
          }
        },
        "59825bac174e41c19cff080e76c084cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a419fa23d0410eab42cdd2e7f6c6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "198d7c7c59804e12bfd1d5a07a65093b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1aded53fb8d4da99702a596aa0ace18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f061e6e6f845958207f9488f902b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "174c0cd51c37474bb926a7025a69b77f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfe9039641a1470ba20e623bbc5a30ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}